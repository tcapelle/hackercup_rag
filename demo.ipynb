{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/tcapelle/hackercup_rag/blob/main/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{rag-hackercup} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "\n",
    "# Introduction\n",
    "\n",
    "\n",
    "</a>\n",
    "\n",
    "\n",
    "In this notebook, we will build a few Code Generation agents for the [HackerCup AI](https://hackercupai.github.io/) challenge.\n",
    "\n",
    "We will build three different agents using different techniques and evaluate them using [W&B Weave](https://weave-docs.wandb.ai/).\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/wandb/weave/master/docs/static/img/evals-hero.png\" width=\"800\" height=\"450\">\n",
    "\n",
    "A more detailed walkthough of the approach we will use in this notebook can be found in the following Youtube video:\n",
    "Hint: Click on the image to watch the video 😎\n",
    "\n",
    "<a target=\"_blank\" href=\"https://www.youtube.com/watch?v=cObBj2UpWK8\">\n",
    "<img src=\"https://img.youtube.com/vi/cObBj2UpWK8/0.jpg\" width=\"600\" height=\"450\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weave\n",
    "\n",
    "\n",
    "Weave is a lightweight toolkit for tracking and evaluating LLM applications, built by Weights & Biases. We will use the following weave to trace and evaluate the various agents we build.\n",
    "\n",
    "We will use Weave to keep track and evaluate the different agents we build.\n",
    "\n",
    "Our goal is to bring rigor, best-practices, and composability to the inherently experimental process of developing AI applications, without introducing cognitive overhead.\n",
    "\n",
    "If you want to learn more about Weave, you can [get started](https://weave-docs.wandb.ai/quickstart) by decorating Python functions with `@weave.op`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: You need to run this cell only once**\n",
    "We will clone the starter-kits repo\n",
    "Set the rag folder as our working directory\n",
    "and install the dependencies for the project.\n",
    "\n",
    "**You can comment out the cell after you have run it once.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "[Errno 2] No such file or directory: 'hackercup_rag'\n",
      "/Users/tcapelle/work/hackercup_rag\n",
      "Requirement already satisfied: bm25s==0.1.10 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.1.10)\n",
      "Requirement already satisfied: datasets==2.21.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.21.0)\n",
      "Requirement already satisfied: instructor==1.4.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: joblib==1.4.2 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: openai==1.43.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (1.43.0)\n",
      "Requirement already satisfied: pandas==2.2.2 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (2.2.2)\n",
      "Requirement already satisfied: pydantic==2.8.2 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (2.8.2)\n",
      "Requirement already satisfied: scikit_learn==1.5.1 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.5.1)\n",
      "Requirement already satisfied: simple_parsing==0.1.5 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (0.1.5)\n",
      "Requirement already satisfied: tree_sitter_languages==1.10.2 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (1.10.2)\n",
      "Requirement already satisfied: tree-sitter==0.21.3 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (0.21.3)\n",
      "Requirement already satisfied: weave==0.50.14 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (0.50.14)\n",
      "Requirement already satisfied: sentence-transformers==3.0.1 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (3.0.1)\n",
      "Requirement already satisfied: litellm in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (1.44.17)\n",
      "Requirement already satisfied: scipy in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from bm25s==0.1.10->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: numpy in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from bm25s==0.1.10->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: filelock in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from datasets==2.21.0->-r requirements.txt (line 2)) (3.14.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from datasets==2.21.0->-r requirements.txt (line 2)) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from datasets==2.21.0->-r requirements.txt (line 2)) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from datasets==2.21.0->-r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from datasets==2.21.0->-r requirements.txt (line 2)) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from datasets==2.21.0->-r requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from datasets==2.21.0->-r requirements.txt (line 2)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==2.21.0->-r requirements.txt (line 2)) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from datasets==2.21.0->-r requirements.txt (line 2)) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from datasets==2.21.0->-r requirements.txt (line 2)) (0.23.3)\n",
      "Requirement already satisfied: packaging in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from datasets==2.21.0->-r requirements.txt (line 2)) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from datasets==2.21.0->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: docstring-parser<0.17,>=0.16 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from instructor==1.4.0->-r requirements.txt (line 3)) (0.16)\n",
      "Requirement already satisfied: jiter<0.5.0,>=0.4.1 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from instructor==1.4.0->-r requirements.txt (line 3)) (0.4.2)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from instructor==1.4.0->-r requirements.txt (line 3)) (2.20.1)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from instructor==1.4.0->-r requirements.txt (line 3)) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.4.1 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from instructor==1.4.0->-r requirements.txt (line 3)) (8.5.0)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.9.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from instructor==1.4.0->-r requirements.txt (line 3)) (0.12.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from openai==1.43.0->-r requirements.txt (line 5)) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from openai==1.43.0->-r requirements.txt (line 5)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from openai==1.43.0->-r requirements.txt (line 5)) (0.27.2)\n",
      "Requirement already satisfied: sniffio in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from openai==1.43.0->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from openai==1.43.0->-r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from pandas==2.2.2->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from pandas==2.2.2->-r requirements.txt (line 6)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from pandas==2.2.2->-r requirements.txt (line 6)) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from pydantic==2.8.2->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from scikit_learn==1.5.1->-r requirements.txt (line 8)) (3.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from weave==0.50.14->-r requirements.txt (line 12)) (0.7.0)\n",
      "Requirement already satisfied: aiofiles>=22.1.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from weave==0.50.14->-r requirements.txt (line 12)) (24.1.0)\n",
      "Requirement already satisfied: aioprocessing>=2.0.1 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from weave==0.50.14->-r requirements.txt (line 12)) (2.0.1)\n",
      "Requirement already satisfied: Werkzeug>=3.0.3 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from weave==0.50.14->-r requirements.txt (line 12)) (3.0.4)\n",
      "Requirement already satisfied: janus>=1.0.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from weave==0.50.14->-r requirements.txt (line 12)) (1.0.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from weave==0.50.14->-r requirements.txt (line 12)) (2.0.7)\n",
      "Requirement already satisfied: wandb>=0.16.4 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from weave==0.50.14->-r requirements.txt (line 12)) (0.17.7)\n",
      "Requirement already satisfied: graphql-core>3 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from weave==0.50.14->-r requirements.txt (line 12)) (3.2.3)\n",
      "Requirement already satisfied: gql>=3.4.1 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from gql[requests]>=3.4.1->weave==0.50.14->-r requirements.txt (line 12)) (3.5.0)\n",
      "Requirement already satisfied: analytics-python>=1.2.9 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from weave==0.50.14->-r requirements.txt (line 12)) (1.2.9)\n",
      "Requirement already satisfied: emoji>=2.12.1 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from weave==0.50.14->-r requirements.txt (line 12)) (2.12.1)\n",
      "Requirement already satisfied: uuid-utils>=0.9.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from weave==0.50.14->-r requirements.txt (line 12)) (0.9.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from sentence-transformers==3.0.1->-r requirements.txt (line 13)) (4.43.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from sentence-transformers==3.0.1->-r requirements.txt (line 13)) (2.4.0)\n",
      "Requirement already satisfied: Pillow in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from sentence-transformers==3.0.1->-r requirements.txt (line 13)) (10.4.0)\n",
      "Requirement already satisfied: click in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from litellm->-r requirements.txt (line 14)) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from litellm->-r requirements.txt (line 14)) (8.4.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from litellm->-r requirements.txt (line 14)) (3.1.4)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from litellm->-r requirements.txt (line 14)) (4.22.0)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from litellm->-r requirements.txt (line 14)) (1.0.1)\n",
      "Requirement already satisfied: tokenizers in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from litellm->-r requirements.txt (line 14)) (0.19.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from aiohttp->datasets==2.21.0->-r requirements.txt (line 2)) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from aiohttp->datasets==2.21.0->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from aiohttp->datasets==2.21.0->-r requirements.txt (line 2)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from aiohttp->datasets==2.21.0->-r requirements.txt (line 2)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from aiohttp->datasets==2.21.0->-r requirements.txt (line 2)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from aiohttp->datasets==2.21.0->-r requirements.txt (line 2)) (1.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from analytics-python>=1.2.9->weave==0.50.14->-r requirements.txt (line 12)) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai==1.43.0->-r requirements.txt (line 5)) (3.8)\n",
      "Requirement already satisfied: backoff<3.0,>=1.11.1 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from gql>=3.4.1->gql[requests]>=3.4.1->weave==0.50.14->-r requirements.txt (line 12)) (2.2.1)\n",
      "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from gql[requests]>=3.4.1->weave==0.50.14->-r requirements.txt (line 12)) (1.0.0)\n",
      "Requirement already satisfied: certifi in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai==1.43.0->-r requirements.txt (line 5)) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai==1.43.0->-r requirements.txt (line 5)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.43.0->-r requirements.txt (line 5)) (0.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm->-r requirements.txt (line 14)) (3.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.2->litellm->-r requirements.txt (line 14)) (2.1.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm->-r requirements.txt (line 14)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm->-r requirements.txt (line 14)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm->-r requirements.txt (line 14)) (0.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from requests>=2.32.2->datasets==2.21.0->-r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from requests>=2.32.2->datasets==2.21.0->-r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from rich<14.0.0,>=13.7.0->instructor==1.4.0->-r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from rich<14.0.0,>=13.7.0->instructor==1.4.0->-r requirements.txt (line 3)) (2.18.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from tiktoken>=0.4.0->weave==0.50.14->-r requirements.txt (line 12)) (2024.7.24)\n",
      "Requirement already satisfied: sympy in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers==3.0.1->-r requirements.txt (line 13)) (1.13.1)\n",
      "Requirement already satisfied: networkx in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers==3.0.1->-r requirements.txt (line 13)) (3.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers==3.0.1->-r requirements.txt (line 13)) (0.4.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from typer<1.0.0,>=0.9.0->instructor==1.4.0->-r requirements.txt (line 3)) (1.5.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from wandb>=0.16.4->weave==0.50.14->-r requirements.txt (line 12)) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from wandb>=0.16.4->weave==0.50.14->-r requirements.txt (line 12)) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from wandb>=0.16.4->weave==0.50.14->-r requirements.txt (line 12)) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from wandb>=0.16.4->weave==0.50.14->-r requirements.txt (line 12)) (5.27.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from wandb>=0.16.4->weave==0.50.14->-r requirements.txt (line 12)) (6.0.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from wandb>=0.16.4->weave==0.50.14->-r requirements.txt (line 12)) (2.13.0)\n",
      "Requirement already satisfied: setproctitle in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from wandb>=0.16.4->weave==0.50.14->-r requirements.txt (line 12)) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from wandb>=0.16.4->weave==0.50.14->-r requirements.txt (line 12)) (73.0.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.16.4->weave==0.50.14->-r requirements.txt (line 12)) (4.0.11)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor==1.4.0->-r requirements.txt (line 3)) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers==3.0.1->-r requirements.txt (line 13)) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.16.4->weave==0.50.14->-r requirements.txt (line 12)) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "# Clone the starter-kits repo\n",
    "!git clone https://github.com/tcapelle/hackercup_rag\n",
    "# Change directory to the rag folder. Running the next line twice in the same session will raise an error.\n",
    "%cd hackercup_rag\n",
    "# Install dependencies\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: capecape.\n",
      "View Weave data at https://wandb.ai/capecape/hackercup/weave\n"
     ]
    }
   ],
   "source": [
    "import weave\n",
    "\n",
    "WEAVE_PROJECT = \"hackercup\"\n",
    "weave_client = weave.init(WEAVE_PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We will use [HackerCup dataset](https://huggingface.co/datasets/hackercupai/hackercup) in this notebook.\n",
    "\n",
    "Specifically, the **practice** dataset from the **2023** season.\n",
    "\n",
    "We have already processed the dataset and saved it as a [`weave.Dataset`](https://weave-docs.wandb.ai/guides/core-types/datasets/). You can either use the Dataset by running the next cell or download the dataset using the instructions below.\n",
    "\n",
    "We will use the dataset to load some practice problems and solutions from the HackerCup dataset and evaluate our agents on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Problem:\n",
      "\n",
      " {\n",
      "  \"problem_dir\": \"data/2023/practice\",\n",
      "  \"problem_name\": \"two_apples_a_day\",\n",
      "  \"problem_description\": \"“An apple a day keeps the doctor away” is Steve’s motto. His other motto, “You can never have too much of a good thing,” holds true for both apples and mottos. Steve would like to eat two apples per day for the next \\\\(N\\\\) days, but with strict adherence to his third motto “Consistency is key.” Specifically, he’d like the sum of the two apple weights he eats over the next \\\\(N\\\\) days to be the same for each day.\\n\\nSteve has already purchased \\\\(2*N-1\\\\) apples, the \\\\(i\\\\)th of which weighs \\\\(A_i\\\\) ounces. He'd like to buy one more apple that's as light as possible to fulfill his goal. Steve can buy an apple of any positive integer weight in ounces from the store. Is it possible for him to reach his goal, and if so, what weight apple should he buy?\\n\\n{{PHOTO_ID:1563872647765708|WIDTH:600}}\\n\\n\\n*The above image depicts the solution to the first sample. Each day, Steve will eat two apples totalling \\\\(7\\\\) oz. Steve must buy a \\\\(4\\\\) oz apple to make this happen.*\\n\\n# Constraints\\n\\\\(1 \\\\leq T \\\\leq 70\\\\)\\n\\\\(1 \\\\leq N \\\\leq 3*10^5\\\\)\\nThe sum of \\\\(N\\\\) over all cases is at most \\\\(600{,}000\\\\)\\n\\\\(1 \\\\leq A_i \\\\leq  10^9\\\\)\\n\\n# Input Format\\nInput begins with an integer \\\\(T\\\\), the number of test cases. Each test case starts with a single integer \\\\(N\\\\). The next line contains \\\\(2*N-1\\\\) space-separated integers \\\\(A_1, ..., A_{2*N - 1}\\\\).\\n\\n# Output Format\\nFor the \\\\(i\\\\)th test case, print \\\"`Case #i:` \\\" followed a single integer, the smallest possible apple weight in ounces that Steve can buy so that he can eat two apples for the next \\\\(N\\\\) days and have the sum of apple weights be the same every day, or \\\\(-1\\\\) if doing so is impossible.\\n\\n# Sample Explanation\\n\\nIn the first case, if Steve buys a \\\\(4\\\\) oz apple, he can group his apples as shown above. For this input, there's no way to succeed by buying any apple below \\\\(4\\\\) oz.\\n\\nIn the second case, Steve can buy a \\\\(7\\\\) oz apple, and eat two apples totaling \\\\(14\\\\) oz each day.\\n\\nIn the third case, any apple weight will suffice, so Steve will buy the lightest one possible.\\n\\nIn the fourth case, no matter what weight apple Steve attempts to buy, it is impossible for him to achieve his goal.\\n\\nPlease note, as demonstrated in the seventh case, that it's possible for the answer to exceed \\\\(10^9\\\\).\\n\\n\\n\",\n",
      "  \"sample_input\": \"7\\n3\\n6 3 1 2 5\\n2\\n7 7 7\\n1\\n1\\n3\\n1 9 1 1 4\\n4\\n1 9 1 1 4 9 9\\n4\\n1 9 10 1 4 6 9\\n3\\n1000000000 2 10 4 999999994\\n\",\n",
      "  \"sample_output\": \"Case #1: 4\\nCase #2: 7\\nCase #3: 1\\nCase #4: -1\\nCase #5: 6\\nCase #6: -1\\nCase #7: 1000000002\\n\",\n",
      "  \"problem_input\": \"data/2023/practice/two_apples_a_day.in\",\n",
      "  \"problem_output\": \"data/2023/practice/two_apples_a_day.out\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "from utils import (\n",
    "    Problem,\n",
    "    Solution,\n",
    "    check_correctness,\n",
    "    async_client,\n",
    "    FAST_LLM,\n",
    "    STRONG_LLM,\n",
    "    format_response,\n",
    ")\n",
    "\n",
    "\n",
    "practice_dataset_uri = \"weave:///parambharat/hackercup/object/practice_dataset:R35fXf9N3FE2IOesg7bRPaPAxiE9YbpirhXO9HcHs8w\"\n",
    "problems_dataset = weave.ref(practice_dataset_uri).get().rows[:]\n",
    "problems = list(map(lambda x: Problem(**x), problems_dataset))\n",
    "problem = problems[0]\n",
    "print(\"Sample Problem:\\n\\n\", problem.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can download the dataset by running the download script from the [submit-first-solution](https://github.com/HackerCupAI/starter-kits/tree/main/submit_first_solution). Specifically, you can run the following command to download the dataset:\n",
    "\n",
    "```bash\n",
    "python download.py --year 2023 --dataset_folder data\n",
    "```\n",
    "\n",
    "\n",
    "This should create a `dataset` folder with the problems and solutions.\n",
    "\n",
    "Here's an example of what the data looks like for the `dim_sum_delivery` problem from the `2023` season:\n",
    "\n",
    "```\n",
    "data/dataset/2023/practice\n",
    "...\n",
    "├── dim_sum_delivery.cpp\n",
    "├── dim_sum_delivery.in\n",
    "├── dim_sum_delivery.md\n",
    "├── dim_sum_delivery.out\n",
    "├── dim_sum_delivery_sample_input.txt\n",
    "├── dim_sum_delivery_sample_output.txt\n",
    "├── dim_sum_delivery_sol.md\n",
    "...\n",
    "```\n",
    "\n",
    "Each problem has a `in`, `out`, `md`, `cpp`, and `sol` file.\n",
    "\n",
    "The `in` file contains the input data for the problem.\n",
    "The `out` file contains the expected output for the problem.\n",
    "The `md` file contains the problem statement.\n",
    "The `cpp` file contains the source code to the solution.\n",
    "The `sol` file contains the detailed solution to the problem.\n",
    "The `sample_input.txt` and `sample_output.txt` files contain the sample input and output for the problem. These are the test cases that will be available to the agent during development and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "\n",
    "from nest_asyncio import apply\n",
    "\n",
    "apply()\n",
    "\n",
    "# Some logging to see the progress\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a way to load a problem and evaluate a solution, let's define a prompt to solve the problem and create a simple agent to solve the problem. \n",
    "\n",
    "Here'e one such prompt we will use to solve the problem, it contains instructions for the model on how to solve the problem and the format of the response we expect from the model. Feel free to tweak the prompt if you like but this should work decently well for our use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "While the RAG agent is an improvement over the zero-shot agent, it's still not perfect.\n",
    "It's still susceptible to hallucinations and incorrect solutions. \n",
    "One way to mitigate this is to use reflection.\n",
    "We can use another LLM call to reflect on the solution and test results and improve it.\n",
    "We can then use the improved solution to generate new few-shot examples and repeat the process in a loop until we converge to a solution or the iteration limit is reached.\n",
    "\n",
    "Again, this is not the best approach to solve the problem and has a lot of room for improvement, but it should help us get towards a working solution.\n",
    "\n",
    "Here are the reflection instructions we will provide to the LLM to reflect on the solution and test results, feel free to change the instructions to improve the agent's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 20:07:10,209 : INFO : PyTorch version 2.4.0 available.\n",
      "2024-09-05 20:07:12,512 : INFO : Use pytorch device_name: mps\n",
      "2024-09-05 20:07:12,512 : INFO : Load pretrained SentenceTransformer: jinaai/jina-embeddings-v2-base-code\n",
      "2024-09-05 20:07:20,990 : DEBUG : Building index from IDs objects      \n",
      "                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a world-class competitive programmer with a keen eye for detail and problem solving. \n",
      "Your expertise is in algorithms and data structures. \n",
      "You have incorrectly answered the following programming problem. \n",
      "Your task is to reflect on the problem, your solution, and the correct answer.\n",
      "You will then use this information help you answer the same question in the future. \n",
      "First, explain why you answered the question incorrectly.\n",
      "Second, list the keywords that describe the type of your errors from most general to most specific.\n",
      "Third, solve the problem again, step-by-step, based on your knowledge of the correct answer.\n",
      "Fourth, create a list of detailed instructions to help you correctly solve this problem in the future.\n",
      "Finally, create a list of general advice to help you solve similar types of problems in the future.\n",
      "Be concise in your response; however, capture all of the essential information.\n",
      "\n",
      "{problem}\n",
      "<incorrect_solution>\n",
      "{incorrect_solution}\n",
      "</incorrect_solution>\n",
      "<test_report>\n",
      "{test_report}\n",
      "</test_report>\n",
      "\n",
      "**Format Instructions: Your response must follow the following xml format** -\n",
      "\n",
      "<root>\n",
      "<reflection>\n",
      "[Reflect on the problem, your solution, and the correct answer.]\n",
      "</reflection>\n",
      "<keywords>\n",
      "[List the keywords that describe the type of your errors from most general to most specific.]\n",
      "</keywords>\n",
      "<step_by_step_solution>\n",
      "[Solve the problem again, step-by-step, based on your knowledge of the correct answer.]\n",
      "</step_by_step_solution>\n",
      "<instructions>\n",
      "[Create a list of detailed instructions to help you correctly solve this problem in the future.]\n",
      "</instructions>\n",
      "<general_advice>\n",
      "[Create a list of general advice to help you solve similar types of problems in the future.]\n",
      "</general_advice>\n",
      "</root>\n",
      "---\n",
      "Let's think step by step to reflect on the problem:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from agent import rag_solver\n",
    "from retriever import Retriever\n",
    "\n",
    "retriever = Retriever()\n",
    "\n",
    "from agent import REFLECTION_INSTRUCTIONS, rework_solution\n",
    "\n",
    "print(REFLECTION_INSTRUCTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op\n",
    "async def rag_solver_with_reflection(\n",
    "        retriever: Retriever,\n",
    "        problem: Problem,\n",
    "        model: str = FAST_LLM,\n",
    "        temperature: float = 0.1,\n",
    "        max_iterations: int = 2,\n",
    "        timeout: int = 10,\n",
    "):\n",
    "    num_iterations = 0\n",
    "    test_report = \"failed\"\n",
    "    solution = None\n",
    "    while not test_report == \"passed\" and num_iterations < max_iterations:\n",
    "        rag_result = await rag_solver(\n",
    "            retriever=retriever,\n",
    "            problem=problem,\n",
    "            timeout=timeout,\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        solution = rag_result[\"solution\"]\n",
    "        test_report = rag_result[\"test_report\"]\n",
    "        if test_report == \"passed\":\n",
    "            return rag_result\n",
    "        rework_result = await rework_solution(\n",
    "            problem=problem,\n",
    "            incorrect_solution=solution,\n",
    "            test_report=test_report,\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            timeout=timeout,\n",
    "        )\n",
    "        solution = rework_result[\"solution\"]\n",
    "        test_report = rework_result[\"test_report\"]\n",
    "        if test_report == \"passed\":\n",
    "            return {\n",
    "                \"solution\": solution,\n",
    "                \"stage\": \"reflection\",\n",
    "                \"test_report\": test_report,\n",
    "            }\n",
    "        num_iterations += 1\n",
    "    logger.info(\"Failed to generate a solution\")\n",
    "    return {\"solution\": solution, \"stage\": \"failed\", \"test_report\": test_report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 20:07:26,059 : INFO : Drafting intial zero-shot solution\n",
      "\u001b[92m20:07:29 - LiteLLM:INFO\u001b[0m: utils.py:2975 - \n",
      "LiteLLM completion() model= open-mistral-nemo-2407; provider = mistral\n",
      "2024-09-05 20:07:29,229 : INFO : \n",
      "LiteLLM completion() model= open-mistral-nemo-2407; provider = mistral\n",
      "2024-09-05 20:07:35,141 : INFO : HTTP Request: POST http://195.242.24.252:8000/v1/chat/completions \"HTTP/1.1 500 Internal Server Error\"\n",
      "2024-09-05 20:07:35,143 : INFO : Retrying request to /chat/completions in 0.891386 seconds\n",
      "2024-09-05 20:07:41,120 : INFO : HTTP Request: POST http://195.242.24.252:8000/v1/chat/completions \"HTTP/1.1 500 Internal Server Error\"\n",
      "2024-09-05 20:07:41,125 : INFO : Retrying request to /chat/completions in 1.788977 seconds\n",
      "2024-09-05 20:07:47,993 : INFO : HTTP Request: POST http://195.242.24.252:8000/v1/chat/completions \"HTTP/1.1 500 Internal Server Error\"\n",
      "\u001b[92m20:07:48 - LiteLLM:INFO\u001b[0m: utils.py:2975 - \n",
      "LiteLLM completion() model= open-mistral-nemo-2407; provider = mistral\n",
      "2024-09-05 20:07:48,040 : INFO : \n",
      "LiteLLM completion() model= open-mistral-nemo-2407; provider = mistral\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 20:07:53,125 : INFO : HTTP Request: POST http://195.242.24.252:8000/v1/chat/completions \"HTTP/1.1 500 Internal Server Error\"\n",
      "2024-09-05 20:07:53,127 : INFO : Retrying request to /chat/completions in 0.995690 seconds\n",
      "2024-09-05 20:07:59,199 : INFO : HTTP Request: POST http://195.242.24.252:8000/v1/chat/completions \"HTTP/1.1 500 Internal Server Error\"\n",
      "2024-09-05 20:07:59,203 : INFO : Retrying request to /chat/completions in 1.703953 seconds\n",
      "2024-09-05 20:08:05,999 : INFO : HTTP Request: POST http://195.242.24.252:8000/v1/chat/completions \"HTTP/1.1 500 Internal Server Error\"\n",
      "\u001b[92m20:08:06 - LiteLLM:INFO\u001b[0m: utils.py:2975 - \n",
      "LiteLLM completion() model= open-mistral-nemo-2407; provider = mistral\n",
      "2024-09-05 20:08:06,017 : INFO : \n",
      "LiteLLM completion() model= open-mistral-nemo-2407; provider = mistral\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 20:08:11,096 : INFO : HTTP Request: POST http://195.242.24.252:8000/v1/chat/completions \"HTTP/1.1 500 Internal Server Error\"\n",
      "2024-09-05 20:08:11,097 : INFO : Retrying request to /chat/completions in 0.770683 seconds\n",
      "2024-09-05 20:08:16,954 : INFO : HTTP Request: POST http://195.242.24.252:8000/v1/chat/completions \"HTTP/1.1 500 Internal Server Error\"\n",
      "2024-09-05 20:08:16,957 : INFO : Retrying request to /chat/completions in 1.654221 seconds\n",
      "2024-09-05 20:08:23,690 : INFO : HTTP Request: POST http://195.242.24.252:8000/v1/chat/completions \"HTTP/1.1 500 Internal Server Error\"\n",
      "2024-09-05 20:08:23,707 : ERROR : Failed after retries: <bound method Future.exception of <Future at 0x33e11cd90 state=finished raised APIError>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/llms/openai.py\", line 1089, in acompletion\n",
      "    headers, response = await self.make_openai_chat_completion_request(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/llms/openai.py\", line 793, in make_openai_chat_completion_request\n",
      "    raise e\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/llms/openai.py\", line 781, in make_openai_chat_completion_request\n",
      "    await openai_aclient.chat.completions.with_raw_response.create(\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/openai/_legacy_response.py\", line 367, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py\", line 333, in wrapper\n",
      "    res, _ = await _execute_call(wrapper, call, *args, **kwargs)  # type: ignore\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py\", line 213, in _call_async\n",
      "    return handle_exception(e)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py\", line 211, in _call_async\n",
      "    res = await func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/weave/integrations/openai/openai_sdk.py\", line 288, in _wrapper\n",
      "    return await fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/openai/_base_client.py\", line 1596, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/openai/_base_client.py\", line 1596, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.InternalServerError: Error code: 500 - {'error': 'Internal server error'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/main.py\", line 427, in acompletion\n",
      "    response = await init_response\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/llms/openai.py\", line 1136, in acompletion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.openai.OpenAIError: Error code: 500 - {'error': 'Internal server error'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/instructor/retry.py\", line 239, in retry_async\n",
      "    response: ChatCompletion = await func(*args, **kwargs)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py\", line 333, in wrapper\n",
      "    res, _ = await _execute_call(wrapper, call, *args, **kwargs)  # type: ignore\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py\", line 213, in _call_async\n",
      "    return handle_exception(e)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py\", line 211, in _call_async\n",
      "    res = await func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/utils.py\", line 1593, in wrapper_async\n",
      "    raise e\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/utils.py\", line 1413, in wrapper_async\n",
      "    result = await original_function(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/main.py\", line 449, in acompletion\n",
      "    raise exception_type(\n",
      "          ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/utils.py\", line 8187, in exception_type\n",
      "    raise e\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/utils.py\", line 6581, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: MistralException - Error code: 500 - {'error': 'Internal server error'}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/instructor/retry.py\", line 235, in retry_async\n",
      "    async for attempt in max_retries:\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tcapelle/miniforge3/envs/weave/lib/python3.11/site-packages/tenacity/__init__.py\", line 419, in exc_check\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x33e11cd90 state=finished raised APIError>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n"
     ]
    },
    {
     "ename": "InstructorRetryException",
     "evalue": "RetryError[<Future at 0x33e11cd90 state=finished raised APIError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/llms/openai.py:1089\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.acompletion\u001b[0;34m(self, data, model_response, logging_obj, timeout, api_key, api_base, organization, client, max_retries, headers, drop_params)\u001b[0m\n\u001b[1;32m   1076\u001b[0m logging_obj\u001b[38;5;241m.\u001b[39mpre_call(\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1078\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mopenai_aclient\u001b[38;5;241m.\u001b[39mapi_key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     },\n\u001b[1;32m   1087\u001b[0m )\n\u001b[0;32m-> 1089\u001b[0m headers, response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_openai_chat_completion_request(\n\u001b[1;32m   1090\u001b[0m     openai_aclient\u001b[38;5;241m=\u001b[39mopenai_aclient, data\u001b[38;5;241m=\u001b[39mdata, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   1091\u001b[0m )\n\u001b[1;32m   1092\u001b[0m stringified_response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/llms/openai.py:793\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.make_openai_chat_completion_request\u001b[0;34m(self, openai_aclient, data, timeout)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 793\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/llms/openai.py:781\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.make_openai_chat_completion_request\u001b[0;34m(self, openai_aclient, data, timeout)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    780\u001b[0m     raw_response \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 781\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m openai_aclient\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mwith_raw_response\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    782\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    783\u001b[0m         )\n\u001b[1;32m    784\u001b[0m     )\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/openai/_legacy_response.py:367\u001b[0m, in \u001b[0;36masync_to_raw_response_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m extra_headers\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py:333\u001b[0m, in \u001b[0;36mop.<locals>.op_deco.<locals>.create_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m call \u001b[38;5;241m=\u001b[39m _create_call(wrapper, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m res, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _execute_call(wrapper, call, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py:213\u001b[0m, in \u001b[0;36m_execute_call.<locals>._call_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py:211\u001b[0m, in \u001b[0;36m_execute_call.<locals>._call_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/integrations/openai/openai_sdk.py:288\u001b[0m, in \u001b[0;36mcreate_wrapper_async.<locals>.wrapper.<locals>._add_stream_options.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_usage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[0;32m--> 288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/openai/resources/chat/completions.py:1339\u001b[0m, in \u001b[0;36mAsyncCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1338\u001b[0m validate_response_format(response_format)\n\u001b[0;32m-> 1339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1341\u001b[0m     body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[1;32m   1342\u001b[0m         {\n\u001b[1;32m   1343\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m   1344\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m   1345\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m   1346\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m   1347\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m   1348\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m   1349\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m   1350\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m   1351\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m   1352\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m   1353\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m   1354\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m   1355\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m   1356\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m   1357\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m   1358\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m   1359\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m   1360\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m   1361\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m   1362\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m   1363\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m   1364\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m   1365\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m   1366\u001b[0m         },\n\u001b[1;32m   1367\u001b[0m         completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m   1368\u001b[0m     ),\n\u001b[1;32m   1369\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m   1370\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   1371\u001b[0m     ),\n\u001b[1;32m   1372\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m   1373\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1374\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ChatCompletionChunk],\n\u001b[1;32m   1375\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/openai/_base_client.py:1816\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1813\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1814\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1815\u001b[0m )\n\u001b[0;32m-> 1816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/openai/_base_client.py:1510\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m   1502\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1503\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     remaining_retries: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1509\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1511\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1512\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1513\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1514\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1515\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[1;32m   1516\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/openai/_base_client.py:1596\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[0;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[1;32m   1595\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39maclose()\n\u001b[0;32m-> 1596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m   1597\u001b[0m         input_options,\n\u001b[1;32m   1598\u001b[0m         cast_to,\n\u001b[1;32m   1599\u001b[0m         retries,\n\u001b[1;32m   1600\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m   1601\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1602\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1603\u001b[0m     )\n\u001b[1;32m   1605\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/openai/_base_client.py:1643\u001b[0m, in \u001b[0;36mAsyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1644\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1645\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1646\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[1;32m   1647\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1648\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1649\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/openai/_base_client.py:1596\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[0;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[1;32m   1595\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39maclose()\n\u001b[0;32m-> 1596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m   1597\u001b[0m         input_options,\n\u001b[1;32m   1598\u001b[0m         cast_to,\n\u001b[1;32m   1599\u001b[0m         retries,\n\u001b[1;32m   1600\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m   1601\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1602\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1603\u001b[0m     )\n\u001b[1;32m   1605\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/openai/_base_client.py:1643\u001b[0m, in \u001b[0;36mAsyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1644\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1645\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1646\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[1;32m   1647\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1648\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1649\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/openai/_base_client.py:1611\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[0;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[1;32m   1610\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1613\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1614\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1615\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[1;32m   1620\u001b[0m )\n",
      "\u001b[0;31mInternalServerError\u001b[0m: Error code: 500 - {'error': 'Internal server error'}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/main.py:427\u001b[0m, in \u001b[0;36macompletion\u001b[0;34m(model, messages, functions, function_call, timeout, temperature, top_p, n, stream, stream_options, stop, max_tokens, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, parallel_tool_calls, logprobs, top_logprobs, deployment_id, base_url, api_version, api_key, model_list, extra_headers, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39miscoroutine(init_response):\n\u001b[0;32m--> 427\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m init_response\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/llms/openai.py:1136\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.acompletion\u001b[0;34m(self, data, model_response, logging_obj, timeout, api_key, api_base, organization, client, max_retries, headers, drop_params)\u001b[0m\n\u001b[1;32m   1135\u001b[0m error_headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m   1137\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mstatus_code, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e), headers\u001b[38;5;241m=\u001b[39merror_headers\n\u001b[1;32m   1138\u001b[0m )\n",
      "\u001b[0;31mOpenAIError\u001b[0m: Error code: 500 - {'error': 'Internal server error'}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/instructor/retry.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(func, response_model, validation_context, args, kwargs, max_retries, strict, mode)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRetryError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed after retries: {e.last_attempt.exception}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         raise InstructorRetryException(\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                     \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0m_execute_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0mcall_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0mcall_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1591\u001b[0m                         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_window_fallback_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1592\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1593\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1591\u001b[0m                         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_window_fallback_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1592\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1593\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/main.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(model, messages, functions, function_call, timeout, temperature, top_p, n, stream, stream_options, stop, max_tokens, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, parallel_tool_calls, logprobs, top_logprobs, deployment_id, base_url, api_version, api_key, model_list, extra_headers, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mcustom_llm_provider\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_llm_provider\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"openai\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         raise exception_type(\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   8185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexception_mapping_worked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8186\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"litellm_response_headers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitellm_response_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8187\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8188\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/litellm/utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   8185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexception_mapping_worked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8186\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"litellm_response_headers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitellm_response_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8187\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8188\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAPIError\u001b[0m: litellm.APIError: APIError: MistralException - Error code: 500 - {'error': 'Internal server error'}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/instructor/retry.py:235\u001b[0m, in \u001b[0;36mretry_async\u001b[0;34m(func, response_model, validation_context, args, kwargs, max_retries, strict, mode)\u001b[0m\n\u001b[1;32m    234\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m max_retries:\n\u001b[1;32m    236\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying, attempt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;241m.\u001b[39mretry_state\u001b[38;5;241m.\u001b[39mattempt_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/tenacity/asyncio/__init__.py:166\u001b[0m, in \u001b[0;36mAsyncRetrying.__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_state)\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m do \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/tenacity/asyncio/__init__.py:153\u001b[0m, in \u001b[0;36mAsyncRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/tenacity/_utils.py:99\u001b[0m, in \u001b[0;36mwrap_to_async_func.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs: typing\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/tenacity/__init__.py:419\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m--> 419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x33e11cd90 state=finished raised APIError>]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInstructorRetryException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reflection_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m rag_solver_with_reflection(\n\u001b[1;32m      2\u001b[0m     retriever, problem, max_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(reflection_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolution\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msource_code)\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py:333\u001b[0m, in \u001b[0;36mop.<locals>.op_deco.<locals>.create_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    332\u001b[0m call \u001b[38;5;241m=\u001b[39m _create_call(wrapper, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m res, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _execute_call(wrapper, call, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py:213\u001b[0m, in \u001b[0;36m_execute_call.<locals>._call_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m    211\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m process(res)\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py:211\u001b[0m, in \u001b[0;36m_execute_call.<locals>._call_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m call_context\u001b[38;5;241m.\u001b[39mpush_call(call)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_exception(e)\n",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m, in \u001b[0;36mrag_solver_with_reflection\u001b[0;34m(retriever, problem, model, temperature, max_iterations, timeout)\u001b[0m\n\u001b[1;32m     12\u001b[0m solution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m test_report \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m num_iterations \u001b[38;5;241m<\u001b[39m max_iterations:\n\u001b[0;32m---> 14\u001b[0m     rag_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m rag_solver(\n\u001b[1;32m     15\u001b[0m         retriever\u001b[38;5;241m=\u001b[39mretriever,\n\u001b[1;32m     16\u001b[0m         problem\u001b[38;5;241m=\u001b[39mproblem,\n\u001b[1;32m     17\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m     18\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     19\u001b[0m         temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m     solution \u001b[38;5;241m=\u001b[39m rag_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolution\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     22\u001b[0m     test_report \u001b[38;5;241m=\u001b[39m rag_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_report\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py:333\u001b[0m, in \u001b[0;36mop.<locals>.op_deco.<locals>.create_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    332\u001b[0m call \u001b[38;5;241m=\u001b[39m _create_call(wrapper, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m res, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _execute_call(wrapper, call, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py:213\u001b[0m, in \u001b[0;36m_execute_call.<locals>._call_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m    211\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m process(res)\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py:211\u001b[0m, in \u001b[0;36m_execute_call.<locals>._call_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m call_context\u001b[38;5;241m.\u001b[39mpush_call(call)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_exception(e)\n",
      "File \u001b[0;32m~/work/hackercup_rag/agent.py:348\u001b[0m, in \u001b[0;36mrag_solver\u001b[0;34m(retriever, problem, model, temperature, timeout)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;129m@weave\u001b[39m\u001b[38;5;241m.\u001b[39mop\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrag_solver\u001b[39m(\n\u001b[1;32m    342\u001b[0m     retriever: Retriever,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    346\u001b[0m     timeout: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m    347\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 348\u001b[0m     zero_shot_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m zero_shot_solver(\n\u001b[1;32m    349\u001b[0m         problem\u001b[38;5;241m=\u001b[39mproblem,\n\u001b[1;32m    350\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    351\u001b[0m         temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m    352\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    353\u001b[0m     )\n\u001b[1;32m    354\u001b[0m     solution \u001b[38;5;241m=\u001b[39m zero_shot_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolution\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    355\u001b[0m     test_report \u001b[38;5;241m=\u001b[39m zero_shot_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_report\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py:333\u001b[0m, in \u001b[0;36mop.<locals>.op_deco.<locals>.create_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    332\u001b[0m call \u001b[38;5;241m=\u001b[39m _create_call(wrapper, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m res, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _execute_call(wrapper, call, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py:213\u001b[0m, in \u001b[0;36m_execute_call.<locals>._call_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m    211\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m process(res)\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py:211\u001b[0m, in \u001b[0;36m_execute_call.<locals>._call_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m call_context\u001b[38;5;241m.\u001b[39mpush_call(call)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_exception(e)\n",
      "File \u001b[0;32m~/work/hackercup_rag/agent.py:328\u001b[0m, in \u001b[0;36mzero_shot_solver\u001b[0;34m(problem, model, temperature, timeout)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;129m@weave\u001b[39m\u001b[38;5;241m.\u001b[39mop\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mzero_shot_solver\u001b[39m(\n\u001b[1;32m    325\u001b[0m     problem: Problem, model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m FAST_LLM, temperature: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, timeout: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m    326\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m    327\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDrafting intial zero-shot solution\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 328\u001b[0m     solution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m draft_solution(\n\u001b[1;32m    329\u001b[0m         problem\u001b[38;5;241m=\u001b[39mproblem,\n\u001b[1;32m    330\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    331\u001b[0m         temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m    332\u001b[0m     )\n\u001b[1;32m    333\u001b[0m     test_report \u001b[38;5;241m=\u001b[39m check_correctness(\n\u001b[1;32m    334\u001b[0m         solution\u001b[38;5;241m.\u001b[39msource_code, problem\u001b[38;5;241m.\u001b[39msample_input, problem\u001b[38;5;241m.\u001b[39msample_output, timeout\n\u001b[1;32m    335\u001b[0m     )\n\u001b[1;32m    336\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDraft solution result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(test_report)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py:333\u001b[0m, in \u001b[0;36mop.<locals>.op_deco.<locals>.create_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    332\u001b[0m call \u001b[38;5;241m=\u001b[39m _create_call(wrapper, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m res, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _execute_call(wrapper, call, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py:213\u001b[0m, in \u001b[0;36m_execute_call.<locals>._call_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m    211\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m process(res)\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/weave/trace/op.py:211\u001b[0m, in \u001b[0;36m_execute_call.<locals>._call_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m call_context\u001b[38;5;241m.\u001b[39mpush_call(call)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_exception(e)\n",
      "File \u001b[0;32m~/work/hackercup_rag/agent.py:81\u001b[0m, in \u001b[0;36mdraft_solution\u001b[0;34m(problem, model, temperature)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@weave\u001b[39m\u001b[38;5;241m.\u001b[39mop\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraft_solution\u001b[39m(\n\u001b[1;32m     74\u001b[0m     problem: Problem, model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m FAST_LLM, temperature: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     75\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Solution:\n\u001b[1;32m     76\u001b[0m     user_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproblem\u001b[38;5;241m.\u001b[39mas_xml\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124m---\u001b[39m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124mLet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms think step by step to solve the problem:\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 81\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m async_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     82\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     83\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     84\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: SOLVER_INSTRUCTIONS},\n\u001b[1;32m     85\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_prompt},\n\u001b[1;32m     86\u001b[0m         ],\n\u001b[1;32m     87\u001b[0m         response_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     88\u001b[0m         temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m     89\u001b[0m         max_tokens\u001b[38;5;241m=\u001b[39mMAX_TOKENS,\n\u001b[1;32m     90\u001b[0m         base_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://195.242.24.252:8000/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     91\u001b[0m     )\n\u001b[1;32m     92\u001b[0m     formatted_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m format_response(\n\u001b[1;32m     93\u001b[0m         response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent, Solution\n\u001b[1;32m     94\u001b[0m     )\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m formatted_response\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/instructor/client.py:300\u001b[0m, in \u001b[0;36mAsyncInstructor.create\u001b[0;34m(self, response_model, messages, max_retries, validation_context, strict, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    292\u001b[0m     response_model: \u001b[38;5;28mtype\u001b[39m[T] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    298\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T \u001b[38;5;241m|\u001b[39m Any:\n\u001b[1;32m    299\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_kwargs(kwargs)\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_fn(\n\u001b[1;32m    301\u001b[0m         response_model\u001b[38;5;241m=\u001b[39mresponse_model,\n\u001b[1;32m    302\u001b[0m         validation_context\u001b[38;5;241m=\u001b[39mvalidation_context,\n\u001b[1;32m    303\u001b[0m         max_retries\u001b[38;5;241m=\u001b[39mmax_retries,\n\u001b[1;32m    304\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    305\u001b[0m         strict\u001b[38;5;241m=\u001b[39mstrict,\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    307\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/instructor/patch.py:119\u001b[0m, in \u001b[0;36mpatch.<locals>.new_create_async\u001b[0;34m(response_model, validation_context, max_retries, strict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_create_async\u001b[39m(\n\u001b[1;32m    109\u001b[0m     response_model: \u001b[38;5;28mtype\u001b[39m[T_Model] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: T_ParamSpec\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[1;32m    115\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T_Model:\n\u001b[1;32m    116\u001b[0m     response_model, new_kwargs \u001b[38;5;241m=\u001b[39m handle_response_model(\n\u001b[1;32m    117\u001b[0m         response_model\u001b[38;5;241m=\u001b[39mresponse_model, mode\u001b[38;5;241m=\u001b[39mmode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    118\u001b[0m     )\n\u001b[0;32m--> 119\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m retry_async(\n\u001b[1;32m    120\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    121\u001b[0m         response_model\u001b[38;5;241m=\u001b[39mresponse_model,\n\u001b[1;32m    122\u001b[0m         validation_context\u001b[38;5;241m=\u001b[39mvalidation_context,\n\u001b[1;32m    123\u001b[0m         max_retries\u001b[38;5;241m=\u001b[39mmax_retries,\n\u001b[1;32m    124\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m    125\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mnew_kwargs,\n\u001b[1;32m    126\u001b[0m         strict\u001b[38;5;241m=\u001b[39mstrict,\n\u001b[1;32m    127\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    128\u001b[0m     )\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniforge3/envs/weave/lib/python3.11/site-packages/instructor/retry.py:267\u001b[0m, in \u001b[0;36mretry_async\u001b[0;34m(func, response_model, validation_context, args, kwargs, max_retries, strict, mode)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    266\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed after retries: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mexception\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InstructorRetryException(\n\u001b[1;32m    268\u001b[0m         e,\n\u001b[1;32m    269\u001b[0m         last_completion\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[1;32m    270\u001b[0m         n_attempts\u001b[38;5;241m=\u001b[39mattempt\u001b[38;5;241m.\u001b[39mretry_state\u001b[38;5;241m.\u001b[39mattempt_number,\n\u001b[1;32m    271\u001b[0m         messages\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    272\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontents\u001b[39m\u001b[38;5;124m\"\u001b[39m, kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m, []))\n\u001b[1;32m    273\u001b[0m         ),\n\u001b[1;32m    274\u001b[0m         total_usage\u001b[38;5;241m=\u001b[39mtotal_usage,\n\u001b[1;32m    275\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mInstructorRetryException\u001b[0m: RetryError[<Future at 0x33e11cd90 state=finished raised APIError>]"
     ]
    }
   ],
   "source": [
    "reflection_result = await rag_solver_with_reflection(\n",
    "    retriever, problem, max_iterations=2, timeout=30\n",
    ")\n",
    "\n",
    "print(\"*\" * 80)\n",
    "print(reflection_result[\"solution\"].source_code)\n",
    "print(\"*\" * 80)\n",
    "print(reflection_result[\"test_report\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now, we are ready to evaluate a more complex agent that uses reflection\n",
    "This agent will try to solve the problem using the retriever\n",
    "and if it fails, it will ask the model to reflect on the problem\n",
    "and then re-work the solution\n",
    "and repeat this process for a fixed number of iterations\n",
    "or until the solution is correct or the iteration limit is reached\n",
    "\n",
    "But the best part is that we can use the same evaluation framework we used for the zero-shot and RAG agent to evaluate the RAG reflection agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGReflectionAgent(weave.Model):\n",
    "    retriever: Retriever\n",
    "    max_iterations: int = 2\n",
    "    timeout: int = 30\n",
    "    model: str = STRONG_LLM\n",
    "    temperature: float = 0.0\n",
    "\n",
    "    @weave.op\n",
    "    async def predict(self, problem: Problem):\n",
    "        return await rag_solver_with_reflection(\n",
    "            self.retriever,\n",
    "            Problem(**problem),\n",
    "            model=self.model,\n",
    "            temperature=self.temperature,\n",
    "            max_iterations=self.max_iterations,\n",
    "            timeout=self.timeout,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the RAG reflection agent for all the models and temperatures\n",
    "tasks = []\n",
    "\n",
    "LLM = STRONG_LLM\n",
    "eval_temperatures = [0.0, 0.5]\n",
    "\n",
    "\n",
    "for temperature in eval_temperatures:\n",
    "        rag_reflection_agent = RAGReflectionAgent(\n",
    "            retriever=retriever, model=LLM, temperature=temperature, timeout=30\n",
    "        )\n",
    "        rag_reflection_results = eval.evaluate(rag_reflection_agent)\n",
    "        tasks.append(rag_reflection_results)\n",
    "rag_reflection_results = await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that completes the demo!\n",
    "\n",
    "Key takeaways from this demo:\n",
    "1. We tried to solve some challenging competitive programming problems using LLM agents.\n",
    "2. We tried three different agents:\n",
    "    - Zero-shot agent\n",
    "    - RAG agent\n",
    "    - RAG reflection agent\n",
    "3. We used Weave to evaluate the agents and compare their performance.\n",
    "\n",
    "We hope you found this demo useful and interesting and that it gave you some ideas on how to use LLM agents to solve challenging problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
